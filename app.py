import os
import streamlit as st
import paho.mqtt.client as paho
import json
import time
from PIL import Image

# --- CONFIGURACIÃ“N DE PÃGINA ---
st.set_page_config(page_title="Casa Inteligente - Control por Voz", page_icon="ğŸ™ï¸", layout="centered")

# --- ESTILO VISUAL (idÃ©ntico al panel tÃ¡ctil) ---
st.markdown("""
<style>
[data-testid="stAppViewContainer"] {
    background: linear-gradient(135deg, #ede7f6 0%, #f3e5f5 100%);
}
[data-testid="stHeader"] {
    background: rgba(255,255,255,0.4);
    backdrop-filter: blur(8px);
}
h1 {
    color: #3a2c5a;
    text-align: center;
    font-family: 'Poppins', sans-serif;
    font-weight: 700;
    margin-bottom: 0.2em;
}
h2 {
    color: #5b3f8c;
    text-align: center;
    font-family: 'Poppins', sans-serif;
    margin-bottom: 1em;
}
.card {
    background-color: rgba(255, 255, 255, 0.8);
    padding: 2em;
    border-radius: 16px;
    box-shadow: 0px 3px 10px rgba(0,0,0,0.1);
    margin-top: 1.2em;
    text-align: center;
}
.voice-button {
    background: linear-gradient(135deg, #7e57c2, #9575cd);
    color: white;
    border: none;
    border-radius: 12px;
    padding: 0.8em 2em;
    font-size: 1em;
    font-family: 'Poppins', sans-serif;
    font-weight: 500;
    box-shadow: 0 4px 10px rgba(0,0,0,0.15);
    cursor: pointer;
    transition: all 0.3s ease;
}
.voice-button:hover {
    background: linear-gradient(135deg, #6a1b9a, #7b1fa2);
    transform: scale(1.05);
}
.result-box {
    background-color: rgba(255,255,255,0.9);
    border-radius: 10px;
    padding: 1em;
    margin-top: 1em;
    box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    color: #4a148c;
    font-weight: 500;
    font-family: 'Poppins', sans-serif;
}
</style>
""", unsafe_allow_html=True)

# --- FUNCIONES MQTT (sin cambios) ---
def on_publish(client, userdata, result):
    print("El dato ha sido publicado \n")

def on_message(client, userdata, message):
    global message_received
    time.sleep(2)
    message_received = str(message.payload.decode("utf-8"))
    st.write(message_received)

broker = "broker.mqttdashboard.com"
port = 1883
client1 = paho.Client("sofimajo")
client1.on_message = on_message

# --- INTERFAZ PRINCIPAL ---
st.title("ğŸ  CASA INTELIGENTE")
st.subheader("ğŸ™ï¸ CONTROL POR VOZ")

st.markdown('<div class="card">', unsafe_allow_html=True)

if os.path.exists('voice_ctrl.jpg'):
    image = Image.open('voice_ctrl.jpg')
    st.image(image, width=150)
else:
    st.image("https://cdn-icons-png.flaticon.com/512/727/727245.png", width=100)

st.write("ğŸ”Š Toca el botÃ³n y habla")

# --- BOTÃ“N DE ESCUCHA (sin Bokeh, mismo comportamiento JS) ---
st.markdown("""
<button class="voice-button" id="speak-btn">ğŸ§ Iniciar escucha</button>
<div id="result" class="result-box" style="display:none;"></div>

<script>
let button = document.getElementById("speak-btn");
let resultDiv = document.getElementById("result");

if ('webkitSpeechRecognition' in window) {
  const recognition = new webkitSpeechRecognition();
  recognition.lang = 'es-ES';
  recognition.continuous = false;
  recognition.interimResults = false;

  button.onclick = () => {
    recognition.start();
    button.innerText = "ğŸ™ï¸ Escuchando...";
    button.style.opacity = "0.8";
  };

  recognition.onresult = function(event) {
    const text = event.results[0][0].transcript;
    button.innerText = "ğŸ§ Iniciar escucha";
    button.style.opacity = "1";
    resultDiv.innerHTML = "ğŸ—£ï¸ Comando detectado: <b>" + text + "</b>";
    resultDiv.style.display = "block";
    window.parent.postMessage({type: "speech", value: text}, "*");
  };

  recognition.onerror = function() {
    button.innerText = "ğŸ§ Iniciar escucha";
    button.style.opacity = "1";
  };
} else {
  button.innerText = "MicrÃ³fono no soportado âŒ";
}
</script>
""", unsafe_allow_html=True)

st.markdown('</div>', unsafe_allow_html=True)

# --- MQTT PUBLICACIÃ“N ---
# En Streamlit, el evento JS se recibe con st.session_state o query_params.
# AquÃ­ lo dejamos listo para publicar cuando tengas texto:
speech_input = st.session_state.get("speech_input", None)

if speech_input:
    client1.on_publish = on_publish
    client1.connect(broker, port)
    message = json.dumps({"Act1": speech_input.strip()})
    ret = client1.publish("mensajeproyecto", message)
    st.success(f"ğŸ“¡ Enviado comando: {speech_input}")


